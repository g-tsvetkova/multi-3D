	[train]	trunk.decoder.embed_tokens.weight:	torch.Size([131, 256])
	[train]	trunk.decoder.embed_positions.weight:	torch.Size([8194, 256])
	[train]	trunk.decoder.final_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.final_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.0.self_attn.k_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.0.self_attn.k_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.0.self_attn.v_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.0.self_attn.v_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.0.self_attn.q_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.0.self_attn.q_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.0.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.0.self_attn.out_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.0.self_attn_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.0.self_attn_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.0.fc1.weight:	torch.Size([1024, 256])
	[train]	trunk.decoder.layers.0.fc1.bias:	torch.Size([1024])
	[train]	trunk.decoder.layers.0.fc2.weight:	torch.Size([256, 1024])
	[train]	trunk.decoder.layers.0.fc2.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.0.final_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.0.final_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.1.self_attn.k_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.1.self_attn.k_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.1.self_attn.v_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.1.self_attn.v_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.1.self_attn.q_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.1.self_attn.q_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.1.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.1.self_attn.out_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.1.self_attn_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.1.self_attn_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.1.fc1.weight:	torch.Size([1024, 256])
	[train]	trunk.decoder.layers.1.fc1.bias:	torch.Size([1024])
	[train]	trunk.decoder.layers.1.fc2.weight:	torch.Size([256, 1024])
	[train]	trunk.decoder.layers.1.fc2.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.1.final_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.1.final_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.2.self_attn.k_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.2.self_attn.k_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.2.self_attn.v_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.2.self_attn.v_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.2.self_attn.q_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.2.self_attn.q_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.2.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.2.self_attn.out_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.2.self_attn_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.2.self_attn_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.2.fc1.weight:	torch.Size([1024, 256])
	[train]	trunk.decoder.layers.2.fc1.bias:	torch.Size([1024])
	[train]	trunk.decoder.layers.2.fc2.weight:	torch.Size([256, 1024])
	[train]	trunk.decoder.layers.2.fc2.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.2.final_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.2.final_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.3.self_attn.k_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.3.self_attn.k_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.3.self_attn.v_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.3.self_attn.v_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.3.self_attn.q_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.3.self_attn.q_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.3.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.3.self_attn.out_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.3.self_attn_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.3.self_attn_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.3.fc1.weight:	torch.Size([1024, 256])
	[train]	trunk.decoder.layers.3.fc1.bias:	torch.Size([1024])
	[train]	trunk.decoder.layers.3.fc2.weight:	torch.Size([256, 1024])
	[train]	trunk.decoder.layers.3.fc2.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.3.final_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.3.final_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.4.self_attn.k_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.4.self_attn.k_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.4.self_attn.v_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.4.self_attn.v_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.4.self_attn.q_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.4.self_attn.q_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.4.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.4.self_attn.out_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.4.self_attn_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.4.self_attn_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.4.fc1.weight:	torch.Size([1024, 256])
	[train]	trunk.decoder.layers.4.fc1.bias:	torch.Size([1024])
	[train]	trunk.decoder.layers.4.fc2.weight:	torch.Size([256, 1024])
	[train]	trunk.decoder.layers.4.fc2.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.4.final_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.4.final_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.5.self_attn.k_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.5.self_attn.k_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.5.self_attn.v_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.5.self_attn.v_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.5.self_attn.q_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.5.self_attn.q_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.5.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	trunk.decoder.layers.5.self_attn.out_proj.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.5.self_attn_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.5.self_attn_layer_norm.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.5.fc1.weight:	torch.Size([1024, 256])
	[train]	trunk.decoder.layers.5.fc1.bias:	torch.Size([1024])
	[train]	trunk.decoder.layers.5.fc2.weight:	torch.Size([256, 1024])
	[train]	trunk.decoder.layers.5.fc2.bias:	torch.Size([256])
	[train]	trunk.decoder.layers.5.final_layer_norm.weight:	torch.Size([256])
	[train]	trunk.decoder.layers.5.final_layer_norm.bias:	torch.Size([256])
	[train]	heads.0.0.self_attn.in_proj_weight:	torch.Size([768, 256])
	[train]	heads.0.0.self_attn.in_proj_bias:	torch.Size([768])
	[train]	heads.0.0.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	heads.0.0.self_attn.out_proj.bias:	torch.Size([256])
	[train]	heads.0.0.multihead_attn.in_proj_weight:	torch.Size([768, 256])
	[train]	heads.0.0.multihead_attn.in_proj_bias:	torch.Size([768])
	[train]	heads.0.0.multihead_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	heads.0.0.multihead_attn.out_proj.bias:	torch.Size([256])
	[train]	heads.0.0.linear1.weight:	torch.Size([1024, 256])
	[train]	heads.0.0.linear1.bias:	torch.Size([1024])
	[train]	heads.0.0.linear2.weight:	torch.Size([256, 1024])
	[train]	heads.0.0.linear2.bias:	torch.Size([256])
	[train]	heads.0.0.norm1.weight:	torch.Size([256])
	[train]	heads.0.0.norm1.bias:	torch.Size([256])
	[train]	heads.0.0.norm2.weight:	torch.Size([256])
	[train]	heads.0.0.norm2.bias:	torch.Size([256])
	[train]	heads.0.0.norm3.weight:	torch.Size([256])
	[train]	heads.0.0.norm3.bias:	torch.Size([256])
	[train]	heads.0.1.weight:	torch.Size([256])
	[train]	heads.0.1.bias:	torch.Size([256])
	[train]	heads.0.2.weight:	torch.Size([131, 256])
	[train]	heads.0.2.bias:	torch.Size([131])
	[train]	heads.1.0.self_attn.in_proj_weight:	torch.Size([768, 256])
	[train]	heads.1.0.self_attn.in_proj_bias:	torch.Size([768])
	[train]	heads.1.0.self_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	heads.1.0.self_attn.out_proj.bias:	torch.Size([256])
	[train]	heads.1.0.multihead_attn.in_proj_weight:	torch.Size([768, 256])
	[train]	heads.1.0.multihead_attn.in_proj_bias:	torch.Size([768])
	[train]	heads.1.0.multihead_attn.out_proj.weight:	torch.Size([256, 256])
	[train]	heads.1.0.multihead_attn.out_proj.bias:	torch.Size([256])
	[train]	heads.1.0.linear1.weight:	torch.Size([1024, 256])
	[train]	heads.1.0.linear1.bias:	torch.Size([1024])
	[train]	heads.1.0.linear2.weight:	torch.Size([256, 1024])
	[train]	heads.1.0.linear2.bias:	torch.Size([256])
	[train]	heads.1.0.norm1.weight:	torch.Size([256])
	[train]	heads.1.0.norm1.bias:	torch.Size([256])
	[train]	heads.1.0.norm2.weight:	torch.Size([256])
	[train]	heads.1.0.norm2.bias:	torch.Size([256])
	[train]	heads.1.0.norm3.weight:	torch.Size([256])
	[train]	heads.1.0.norm3.bias:	torch.Size([256])
	[train]	heads.1.1.weight:	torch.Size([256])
	[train]	heads.1.1.bias:	torch.Size([256])
	[train]	heads.1.2.weight:	torch.Size([131, 256])
	[train]	heads.1.2.bias:	torch.Size([131])
	[train]	offset_embeddings.weight:	torch.Size([2, 256])
call with args: Namespace(base_lr=0.0001, final_lr=1e-06, weight_decay=0.1, clip_gradient=0.1, warm_lr=1e-06, warm_lr_iters=1000, pad_id=-1, dataset='objaverse', augment=False, n_discrete_size=128, n_max_triangles=800, model='mesh_xl_mtp', llm='mesh-xl/mesh-xl-125m', text_condition=None, image_condition=None, pretrained_weights=None, dataset_num_workers=1, batchsize_per_gpu=1, start_epoch=0, max_epoch=100, start_eval_after=-1, eval_every_iteration=4000, seed=0, train_from_scratch=True, test_only=False, sample_rounds=100, criterion=None, test_ckpt='', checkpoint_dir='./checkpoints', save_every=20000, log_every=10)
MTPMeshXL(
  (tokenizer): MeshTokenizer()
  (trunk): OPTModel(
    (decoder): OPTDecoder(
      (embed_tokens): Embedding(131, 256, padding_idx=130)
      (embed_positions): OPTLearnedPositionalEmbedding(8194, 256)
      (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-5): 6 x OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (heads): ModuleList(
    (0-1): 2 x Sequential(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): Linear(in_features=256, out_features=131, bias=True)
    )
  )
  (offset_embeddings): Embedding(2, 256)
)
